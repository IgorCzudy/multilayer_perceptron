{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-10-13 13:33:50--  https://raw.githubusercontent.com/karpathy/makemore/master/names.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 228145 (223K) [text/plain]\n",
      "Saving to: ‘names.txt.2’\n",
      "\n",
      "names.txt.2         100%[===================>] 222,80K  --.-KB/s    in 0,06s   \n",
      "\n",
      "2023-10-13 13:33:50 (3,95 MB/s) - ‘names.txt.2’ saved [228145/228145]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/karpathy/makemore/master/names.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"names.txt\", \"r\") as f:\n",
    "    words = f.read().splitlines()\n",
    "words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = set(\"\".join(words + [\".\"]))\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n': 0,\n",
       " 'u': 1,\n",
       " 's': 2,\n",
       " 'f': 3,\n",
       " '.': 4,\n",
       " 'e': 5,\n",
       " 'm': 6,\n",
       " 'o': 7,\n",
       " 'z': 8,\n",
       " 't': 9,\n",
       " 'g': 10,\n",
       " 'q': 11,\n",
       " 'l': 12,\n",
       " 'p': 13,\n",
       " 'k': 14,\n",
       " 'a': 15,\n",
       " 'v': 16,\n",
       " 'y': 17,\n",
       " 'r': 18,\n",
       " 'j': 19,\n",
       " 'w': 20,\n",
       " 'd': 21,\n",
       " 'x': 22,\n",
       " 'b': 23,\n",
       " 'h': 24,\n",
       " 'i': 25,\n",
       " 'c': 26}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itoch = {i:ch for i, ch in enumerate(set(\"\".join(words + [\".\"])))}\n",
    "chtoi = {ch:i for i, ch in itoch.items()}\n",
    "chtoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def make_data(words, block_size=3):\n",
    "    Xs, Ys = [], []\n",
    "    for word in words:\n",
    "        block = [chtoi[\".\"]] * block_size\n",
    "        for letter in word + \".\":\n",
    "            letter_int = chtoi[letter]\n",
    "            Xs.append(block)\n",
    "            Ys.append(letter_int)\n",
    "            block = block[1:] + [letter_int]\n",
    "    return torch.tensor(Xs), torch.tensor(Ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(7)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr, Ytr = make_data(words[:n1])\n",
    "Xval, Yval = make_data(words[n1:n2])\n",
    "Xtest, Ytest = make_data(words[n2:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4,  4,  4],\n",
      "        [ 4,  4,  8],\n",
      "        [ 4,  8, 15],\n",
      "        ...,\n",
      "        [21,  5,  2],\n",
      "        [ 5,  2,  9],\n",
      "        [ 2,  9,  7]])\n",
      "tensor([ 8, 15, 25,  ...,  9,  7,  4])\n"
     ]
    }
   ],
   "source": [
    "print(Xtr)\n",
    "print(Ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xtr = Xtr[:1]\n",
    "# Ytr = Ytr[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two demensional space for every world \n",
    "C = torch.randn((27,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4127,  1.3877],\n",
      "        [-0.4127,  1.3877],\n",
      "        [-0.4127,  1.3877]])\n",
      "tensor(14)\n"
     ]
    }
   ],
   "source": [
    "print(C[Xtr[0]])\n",
    "# ---> need to predict\n",
    "print(Ytr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "assert all(F.one_hot(torch.tensor(4), num_classes=27).float() @ C == C[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass\n",
    "C[Xtr].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[Xtr]\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 6x100)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/igor/code/multilayer_perceptron/multilayer_perceptron.ipynb Komórka 14\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/igor/code/multilayer_perceptron/multilayer_perceptron.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m W \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn((\u001b[39m6\u001b[39m, \u001b[39m100\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/igor/code/multilayer_perceptron/multilayer_perceptron.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m b \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn((\u001b[39m100\u001b[39m,))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/igor/code/multilayer_perceptron/multilayer_perceptron.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m emb \u001b[39m@\u001b[39;49m W \u001b[39m+\u001b[39m b\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 6x100)"
     ]
    }
   ],
   "source": [
    "W = torch.randn((6, 100))\n",
    "b = torch.randn((100,))\n",
    "emb @ W + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4127,  1.3877],\n",
       "         [-0.4127,  1.3877],\n",
       "         [-0.4127,  1.3877]]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4127,  1.3877, -0.4127,  1.3877, -0.4127,  1.3877]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chcemy z emb o wymiaryach 1,3,2 zmienić na wymiary 1, 6 \n",
    "torch.cat((emb[:,0,:], emb[:,1,:], emb[:,2,:]), dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((emb[:,0,:], emb[:,1,:], emb[:,2,:]), dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.6216,  0.3482, -0.0828, -1.3032, -0.1063,  0.1853, -5.0332, -2.7573,\n",
       "          2.0218,  0.7074,  3.8027, -0.2592, -0.5935,  3.7609,  0.3063, -1.7958,\n",
       "          0.6337, -3.4049, -2.2718,  3.5253, -3.8619,  1.9599,  0.6750, -1.6466,\n",
       "          3.7459, -0.3117,  1.4384,  0.5669,  6.7886,  0.8523,  4.2219,  0.3101,\n",
       "          2.9659, -0.2958, -0.9242,  0.4876,  3.6477, -1.2454,  0.0566, -2.1039,\n",
       "         -4.3322,  0.2648, -1.4948,  5.9703, -1.3876,  2.1602, -0.9177,  3.2663,\n",
       "          1.2937, -0.5446, -1.1439,  0.5079,  0.2678,  1.9708,  0.5263, -0.4662,\n",
       "         -2.8326, -3.6063, -0.7960,  0.1086, -0.7372,  1.0902, -0.1860, -0.5168,\n",
       "          0.4198,  0.4554, -3.8034,  1.6933, -2.2972, -1.7961,  2.0506, -2.0018,\n",
       "          2.6003,  1.0769,  0.3389, -3.0098, -4.1756,  5.7027, -1.7722,  0.6083,\n",
       "          0.8145,  4.1647,  0.7487, -1.9342, -0.7743, -3.1810, -1.3212, -2.0557,\n",
       "          0.5819, -1.3590,  2.6757, -7.0366, -2.4989, -4.6825, -1.6527,  0.0792,\n",
       "         -1.6315,  2.4325, -1.2204,  2.6748]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((emb[:,0], emb[:,1], emb[:,2]), dim=1) @ W + b\n",
    "# dla każdego z 27 liter prawdpodobienstwa przed normalizacją "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.4127,  1.3877]]),\n",
       " tensor([[-0.4127,  1.3877]]),\n",
       " tensor([[-0.4127,  1.3877]]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unbind(emb, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4127,  1.3877, -0.4127,  1.3877, -0.4127,  1.3877]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(torch.unbind(emb, 1), 1)\n",
    "# same thing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " -0.41270169615745544\n",
       " 1.3876614570617676\n",
       " -0.41270169615745544\n",
       " 1.3876614570617676\n",
       " -0.41270169615745544\n",
       " 1.3876614570617676\n",
       "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4127,  1.3877, -0.4127,  1.3877, -0.4127,  1.3877]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the best, becouse its only change .storage \n",
    "# to make vie work 1 * 6 == len(emb)\n",
    "emb.view(-1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = torch.randn((6, 100))\n",
    "b = torch.randn((100,))\n",
    "\n",
    "h = torch.tanh(emb.view(-1,6) @ W + b)\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = torch.randn((100, 27))\n",
    "b2 = torch.randn((27,))\n",
    "\n",
    "logits = h @ W2 + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.4335e-08, 7.3455e-05, 2.2849e-05, 7.3862e-10, 8.4030e-02, 7.9087e-02,\n",
       "         6.8150e-06, 3.8965e-09, 4.0158e-05, 6.7844e-06, 9.2947e-07, 8.3669e-01,\n",
       "         8.7415e-10, 9.2508e-09, 2.1681e-09, 1.1023e-11, 2.2570e-08, 4.9096e-15,\n",
       "         1.9839e-05, 5.7018e-10, 1.6492e-19, 5.6202e-08, 2.2967e-06, 1.4468e-05,\n",
       "         6.4654e-09, 1.8073e-09, 6.8012e-07]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = logits.exp()\n",
    "p = counts / counts.sum(1, keepdim=True)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.4335e-08, 7.3455e-05, 2.2849e-05, 7.3862e-10, 8.4030e-02, 7.9087e-02,\n",
       "         6.8150e-06, 3.8965e-09, 4.0158e-05, 6.7844e-06, 9.2947e-07, 8.3669e-01,\n",
       "         8.7415e-10, 9.2508e-09, 2.1681e-09, 1.1023e-11, 2.2570e-08, 4.9096e-15,\n",
       "         1.9839e-05, 5.7018e-10, 1.6492e-19, 5.6202e-08, 2.2967e-06, 1.4468e-05,\n",
       "         6.4654e-09, 1.8072e-09, 6.8012e-07]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "p = F.softmax(logits, dim=1)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(19.9494)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -p[torch.arange(Ytr.shape[0]), Ytr].log().mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(19.9494)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F.cross_entropy w PyTorch to funkcja, która oblicza negative log-likelihood \n",
    "# loss w połączeniu z log_softmax. Oznacza to, że nie musisz stosować osobno softmax i log_softmax\n",
    "loss = F.cross_entropy(logits, Ytr)\n",
    "loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sum up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.randn((27,2))\n",
    "\n",
    "W = torch.randn((6, 100))\n",
    "b = torch.randn(100)\n",
    "\n",
    "W2 = torch.randn((100, 27))\n",
    "b2 = torch.randn(27)\n",
    "\n",
    "parms = [C, W, b, W2, b2]\n",
    "for parm in parms:\n",
    "    parm.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=329.15771484375\n",
      "loss.item()=225.9630889892578\n",
      "loss.item()=192.48878479003906\n",
      "loss.item()=157.08538818359375\n",
      "loss.item()=88.80526733398438\n",
      "loss.item()=58.40372848510742\n",
      "loss.item()=55.04838562011719\n",
      "loss.item()=43.11375427246094\n",
      "loss.item()=52.42787551879883\n",
      "loss.item()=53.36442565917969\n",
      "loss.item()=46.63205337524414\n",
      "loss.item()=44.758872985839844\n",
      "loss.item()=60.14103317260742\n",
      "loss.item()=58.75661849975586\n",
      "loss.item()=58.10542297363281\n",
      "loss.item()=49.84859085083008\n",
      "loss.item()=51.75644302368164\n",
      "loss.item()=42.50431823730469\n",
      "loss.item()=35.068450927734375\n",
      "loss.item()=30.58955955505371\n",
      "loss.item()=29.65923500061035\n",
      "loss.item()=29.001667022705078\n",
      "loss.item()=27.895158767700195\n",
      "loss.item()=28.654075622558594\n",
      "loss.item()=29.265350341796875\n",
      "loss.item()=27.6474609375\n",
      "loss.item()=27.754106521606445\n",
      "loss.item()=26.88087272644043\n",
      "loss.item()=25.506668090820312\n",
      "loss.item()=23.8644962310791\n",
      "loss.item()=23.3826961517334\n",
      "loss.item()=20.55409812927246\n",
      "loss.item()=18.59749412536621\n",
      "loss.item()=20.00882339477539\n",
      "loss.item()=20.813217163085938\n",
      "loss.item()=20.54281997680664\n",
      "loss.item()=19.561857223510742\n",
      "loss.item()=18.93646812438965\n",
      "loss.item()=21.29297637939453\n",
      "loss.item()=21.76665496826172\n",
      "loss.item()=22.177785873413086\n",
      "loss.item()=21.333148956298828\n",
      "loss.item()=22.91545867919922\n",
      "loss.item()=24.981298446655273\n",
      "loss.item()=26.963342666625977\n",
      "loss.item()=29.202625274658203\n",
      "loss.item()=29.524080276489258\n",
      "loss.item()=27.775402069091797\n",
      "loss.item()=26.07819366455078\n",
      "loss.item()=25.116003036499023\n",
      "loss.item()=22.990108489990234\n",
      "loss.item()=21.06160545349121\n",
      "loss.item()=20.403024673461914\n",
      "loss.item()=19.974342346191406\n",
      "loss.item()=21.24465560913086\n",
      "loss.item()=22.417739868164062\n",
      "loss.item()=23.64815902709961\n",
      "loss.item()=24.378280639648438\n",
      "loss.item()=25.21714210510254\n",
      "loss.item()=25.598352432250977\n",
      "loss.item()=24.820587158203125\n",
      "loss.item()=23.684547424316406\n",
      "loss.item()=22.95147705078125\n",
      "loss.item()=21.92729949951172\n",
      "loss.item()=20.56578826904297\n",
      "loss.item()=19.882984161376953\n",
      "loss.item()=20.219655990600586\n",
      "loss.item()=19.863113403320312\n",
      "loss.item()=19.677204132080078\n",
      "loss.item()=19.887813568115234\n",
      "loss.item()=20.342069625854492\n",
      "loss.item()=21.123579025268555\n",
      "loss.item()=20.832469940185547\n",
      "loss.item()=21.09307861328125\n",
      "loss.item()=22.82523536682129\n",
      "loss.item()=23.43593978881836\n",
      "loss.item()=23.588869094848633\n",
      "loss.item()=23.0947208404541\n",
      "loss.item()=21.826316833496094\n",
      "loss.item()=19.839824676513672\n",
      "loss.item()=20.571149826049805\n",
      "loss.item()=21.82363510131836\n",
      "loss.item()=21.059425354003906\n",
      "loss.item()=20.441837310791016\n",
      "loss.item()=21.309856414794922\n",
      "loss.item()=20.940744400024414\n",
      "loss.item()=19.896089553833008\n",
      "loss.item()=19.80389404296875\n",
      "loss.item()=20.290700912475586\n",
      "loss.item()=19.50118064880371\n",
      "loss.item()=19.630386352539062\n",
      "loss.item()=19.15477752685547\n",
      "loss.item()=19.546951293945312\n",
      "loss.item()=19.937402725219727\n",
      "loss.item()=19.821388244628906\n",
      "loss.item()=20.040992736816406\n",
      "loss.item()=20.8563289642334\n",
      "loss.item()=21.420408248901367\n",
      "loss.item()=21.554367065429688\n",
      "loss.item()=21.992298126220703\n"
     ]
    }
   ],
   "source": [
    "for _ in range(100):\n",
    "    # forward\n",
    "    h = torch.tanh(C[Xtr].reshape(-1, 6) @ W  + b)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, Ytr)\n",
    "    print(f'{loss.item()=}')\n",
    "\n",
    "    # backward \n",
    "    loss.backward()\n",
    "    for parm in parms:\n",
    "        parm.data += -0.1 * parm.grad\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
